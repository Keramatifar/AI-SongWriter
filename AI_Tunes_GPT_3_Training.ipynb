{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI-SongWriter GPT-3 Training ",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMwUdHMvYuITMzehHUcLVz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robgon-art/ai-tunes/blob/main/AI_Tunes_GPT_3_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVelIY2TaRy9"
      },
      "source": [
        "# **AI-SongWriter: Creating New Songs with Artificial Intelligence**\n",
        "### ** Fine-tunning OpenAI's GPT-3 to generate music with a specific structure**\n",
        "Mohammad Keramatifar\n based on Ai-Tunes By Robert. A Gonsalves\n",
        "\n",
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAP6FaK9hzTu"
      },
      "source": [
        "##**Initialize the System**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qe6fbeWTc3J"
      },
      "source": [
        "!git clone https://github.com/robgon-art/music-geometry-eval\n",
        "!git clone https://github.com/00sapo/OpenEWLD\n",
        "!gsutil -q -m cp -r gs://magentadata/models/music_transformer/primers/* /content/\n",
        "!gsutil -q -m cp gs://magentadata/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2 /content/\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev\n",
        "!pip install magenta\n",
        "!pip install pyfluidsynth\n",
        "!pip install openai\n",
        "import note_seq\n",
        "SF2_PATH = '/content/Yamaha-C5-Salamander-JNv5.1.sf2'\n",
        "SAMPLE_RATE = 16000\n",
        "\n",
        "!wget https://wim.vree.org/svgParse/xml2abc.py-143.zip\n",
        "!unzip xml2abc.py-143.zip\n",
        "import sys\n",
        "sys.path.append('/content/music-geometry-eval/music_geometry_eval')\n",
        "import music_geometry_eval\n",
        "import glob\n",
        "import random\n",
        "import music21\n",
        "import music_geometry_eval\n",
        "from collections.abc import Iterable\n",
        "import numpy as np\n",
        "random.seed(42)\n",
        "song_files = glob.glob(\"OpenEWLD/dataset/*/*/*.mxl\")\n",
        "random.shuffle(song_files)\n",
        "num_files = len(song_files)\n",
        "print(song_files)\n",
        "print(\"number of song files is\", num_files)\n",
        "\n",
        "transpose_dict = {\"G major\": 5, \"A- major\": 4, \"A major\": 3, \"B- major\": 2, \"B major\": 1, \"C major\": 0, \"D- major\": -1, \"D major\": -2, \"E- major\": -3, \"E major\": -4, \"F major\": -5, \"F# major\": -6}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8k890KUiCe9"
      },
      "source": [
        "##**Evaluate the Song Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxPQe3mEi5_E"
      },
      "source": [
        "keys = {}\n",
        "metres = {}\n",
        "\n",
        "cmm_arr = np.empty((0), np.float32)\n",
        "lm_arr = np.empty((0), np.float32)\n",
        "cent_arr = np.empty((0), np.float32)\n",
        "\n",
        "for s in song_files:\n",
        "  print(\"\\n\" + s)\n",
        "  score = music21.converter.parse(s)\n",
        "\n",
        "  key = None\n",
        "  metre = None\n",
        "  part = score.parts[0]\n",
        "  for p in part:\n",
        "    if isinstance(p, Iterable):\n",
        "      for n in p:\n",
        "        if type(n) == music21.key.Key:\n",
        "          key = n.name\n",
        "        if type(n) == music21.meter.TimeSignature:\n",
        "          metre = n.ratioString\n",
        "\n",
        "  if metre in metres.keys():\n",
        "    metres[metre] += 1\n",
        "  else:\n",
        "    metres[metre] = 1\n",
        "\n",
        "  if key in keys.keys():\n",
        "    keys[key] += 1\n",
        "  else:\n",
        "    keys[key] = 1\n",
        "\n",
        "  if not (metre == \"4/4\" or metre == \"2/2\"):\n",
        "    continue\n",
        "\n",
        "  if not \"major\" in key:\n",
        "    continue\n",
        "\n",
        "  print(key, metre)\n",
        "\n",
        "  if key in keys.keys():\n",
        "    keys[key] += 1\n",
        "  else:\n",
        "    keys[key] = 1\n",
        "\n",
        "  if key in transpose_dict.keys():\n",
        "    interval = transpose_dict[key]\n",
        "    print(\"transposing from key\", key, \"to C major using interval\", interval)\n",
        "    score = score.transpose(interval)\n",
        "\n",
        "  note_array = []\n",
        "\n",
        "  for p in part:\n",
        "    if isinstance(p, Iterable):\n",
        "      for n in p:\n",
        "        if type(n) == music21.note.Note:\n",
        "          note_array.append([int(n.pitch.ps), int(n.quarterLength*4+0.5)])\n",
        "\n",
        "  # print(note_array)\n",
        "\n",
        "  CMM = music_geometry_eval.calculate_time_supported_conjunct_melodic_motion(note_array)\n",
        "  LM = music_geometry_eval.calculate_time_supported_limited_macroharmony(note_array, span_size=32)\n",
        "  CENT = music_geometry_eval.calculate_time_supported_centricity(note_array, span_size=32)\n",
        "\n",
        "  print(\"CMM :\", round(CMM, 4))\n",
        "  print(\"LM  :\", round(LM, 4))\n",
        "  print(\"CENT:\", round(CENT, 4))\n",
        "  \n",
        "  cmm_arr = np.append(cmm_arr, CMM)\n",
        "  lm_arr = np.append(lm_arr, LM)\n",
        "  cent_arr = np.append(cent_arr, CENT)\n",
        "\n",
        "print(metres)\n",
        "print(keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jid4deViGv8"
      },
      "source": [
        "## **Show the Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxWpBVrOZKpq"
      },
      "source": [
        "CMM_mean = cmm_arr.mean()\n",
        "CMM_std = cmm_arr.std()\n",
        "\n",
        "LM_mean = lm_arr.mean()\n",
        "LM_std = lm_arr.std()\n",
        "\n",
        "CENT_mean = cent_arr.mean()\n",
        "CENT_std = cent_arr.std()\n",
        "\n",
        "print(\"Conjunct Melodic Motion (CMM) :\", round(CMM_mean, 4), \"±\", round(CMM_std, 4))\n",
        "print(\"Limited Macroharmony    (LM)  :\", round(LM_mean, 4), \"±\", round(LM_std, 4))\n",
        "print(\"Centricity              (CENT):\", round(CENT_mean, 4), \"±\", round(CENT_std, 4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXx2UXq7iXyN"
      },
      "source": [
        "## **Prepare the Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR5eeHio92KI"
      },
      "source": [
        "import subprocess\n",
        "from collections.abc import Iterable\n",
        "\n",
        "num_prompts = 0\n",
        "prompt_file = open(\"songs.jsonl\", \"w\")\n",
        "prompts = []\n",
        "original_songs = []\n",
        "for s in song_files:\n",
        "  print(s)\n",
        "  score = music21.converter.parse(s)\n",
        "\n",
        "  key = None\n",
        "  metre = None\n",
        "  part = score.parts[0]\n",
        "  for p in part:\n",
        "    if isinstance(p, Iterable):\n",
        "      for n in p:\n",
        "        if type(n) == music21.key.Key:\n",
        "          key = n.name\n",
        "        if type(n) == music21.meter.TimeSignature:\n",
        "          metre = n.ratioString\n",
        "  print(key, metre)\n",
        "\n",
        "  if not (metre == \"4/4\" or metre == \"2/2\"):\n",
        "    continue\n",
        "\n",
        "  if not \"major\" in key:\n",
        "    continue\n",
        "\n",
        "  if key in transpose_dict.keys():\n",
        "    interval = transpose_dict[key]\n",
        "    print(\"transposing from key\", key, \"to C major using interval\", interval)\n",
        "    score = score.transpose(interval)\n",
        "\n",
        "  score.write('xml', fp='song.xml')\n",
        "\n",
        "  try:\n",
        "    output_bytes = subprocess.check_output([\"python\", \"/content/xml2abc_143/xml2abc.py\", \"song.xml\", \"-u\", \"-d\", \"4\"], timeout=5)\n",
        "    output = output_bytes.decode(\"utf-8\").strip()\n",
        "    with open(\"song.txt\", \"w\") as abc_file:\n",
        "      abc_file.write(output)\n",
        "  except:\n",
        "    print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "    continue\n",
        "\n",
        "  showed_title = False\n",
        "  prompt_string = \"\"\n",
        "  completion_string = \"\"\n",
        "  is_header = True\n",
        "  with open(\"song.txt\") as song_file:\n",
        "    lines = song_file.readlines()\n",
        "    for line in lines:\n",
        "      line = line.replace(\"$\", \"\")\n",
        "      line = line.replace(\"dc=\", \"\")\n",
        "      line = line.strip()\n",
        "\n",
        "      if line.startswith(\"V:\"):\n",
        "        is_header = False\n",
        "\n",
        "      if is_header:\n",
        "        if line.startswith(\"X:\") or line.startswith(\"C:\"):\n",
        "          prompt_string += line+\"\\n\"\n",
        "\n",
        "        if line.startswith(\"T:\") and not showed_title:\n",
        "            prompt_string += line+\"\\n\"\n",
        "            showed_title = True\n",
        "      else:\n",
        "        if not line.startswith(\"w:\") and not line.startswith(\"V:\"):\n",
        "\n",
        "          # remove end of line comments\n",
        "          index = line.rfind('%')\n",
        "          if index > 0:\n",
        "            line = line[:index].strip()\n",
        "\n",
        "          # remove inline comments\n",
        "          parts = line.split('\"')\n",
        "          newline = \"\"\n",
        "          for i, p in enumerate(parts):\n",
        "            if i%2 == 0:\n",
        "              newline += p\n",
        "            elif not p.startswith(\"^\"):\n",
        "              newline += '\"' + p + '\"'\n",
        "          line = ' '.join(newline.split())\n",
        "\n",
        "          completion_string += line+\"\\n\"\n",
        "\n",
        "      if line.startswith(\"V:\"):\n",
        "        is_header = False\n",
        "\n",
        "    prompt_string = prompt_string.replace(\":\",\": \")\n",
        "    prompt_string = prompt_string.replace('\"', \"`\")\n",
        "    prompt_string = prompt_string.replace(\"\\n\",\" $ \")\n",
        "\n",
        "    completion_string = completion_string.replace('\"', \"`\")\n",
        "    completion_string = completion_string.strip().replace(\"\\n\",\" $ \")\n",
        "\n",
        "    prompt = '{\"prompt\": \"' + prompt_string + '<song>\", '\n",
        "    prompt += '\"completion\": \" ' + completion_string + ' $ <end>\"}\\n'\n",
        "\n",
        "    if prompt not in prompts:\n",
        "      original_songs.append(s)\n",
        "      prompt_file.write(prompt)\n",
        "      prompts.append(prompt)\n",
        "      num_prompts += 1\n",
        "\n",
        "prompt_file.close()\n",
        "print(\"num prompts is\", num_prompts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4_76slDij7U"
      },
      "source": [
        "# **Check the Training File**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ5gLbUaEkYR"
      },
      "source": [
        "!openai tools fine_tunes.prepare_data -f /content/songs.jsonl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh8MPqvump8m"
      },
      "source": [
        "# **Train GPT-3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5lvuiZLd5Hj"
      },
      "source": [
        "!export OPENAI_API_KEY=\"<Your OpenAI API Key>\"; openai api fine_tunes.create -t songs.jsonl --model curie --n_epochs 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho0Xy7cEmw0t"
      },
      "source": [
        "# **Generate Five Songs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hol2mChWjzrr"
      },
      "source": [
        "import openai\n",
        "import music21\n",
        "import numpy as np\n",
        "from collections.abc import Iterable\n",
        "import numpy as np\n",
        "\n",
        "CMM_mean = 2.2715\n",
        "CMM_std = 0.4831\n",
        "\n",
        "LM_mean = 2.0305\n",
        "LM_std = 0.5386\n",
        "\n",
        "CENT_mean = 0.3042\n",
        "CENT_std = 0.0891\n",
        "\n",
        "band_name = \"I Lost My Voice\"\n",
        "song_name = \"The Rare Pearls\"\n",
        "prompt = \"X: 1 $ T: \" + song_name + \" $ C: \" + band_name + \" $ <song>\"\n",
        "print(prompt)\n",
        "print()\n",
        "\n",
        "openai.api_key = \"<Your OpenAI API Key>\"\n",
        "\n",
        "songs_with_scores = []\n",
        "score_arr = np.empty((0), np.float32)\n",
        "\n",
        "for i in range(5):\n",
        "  print(\"\\n  Generating Song\", i)\n",
        "  response = openai.Completion.create(\n",
        "      model=\"curie:ft-user-j0julqovorjakyuyt3kv3zci-2021-08-24-11-42-59\",\n",
        "      prompt=prompt,\n",
        "      stop = \" $ <end>\",\n",
        "      temperature=0.75,\n",
        "      top_p=1.0,\n",
        "      frequency_penalty=0.0,\n",
        "      presence_penalty=0.0,\n",
        "      max_tokens = 1000)\n",
        "\n",
        "  print(response)\n",
        "  print()\n",
        "\n",
        "  formatted_prompt = \"X: 1 $ T: \" + song_name + \" $ C: \" + band_name + \" $ L: 1/4 $ M: 4/4 $ K: C $ V: 1 treble\"\n",
        "  formatted_prompt = formatted_prompt.replace(\" $ \", \"\\n\")\n",
        "  formatted_prompt = formatted_prompt.replace(\"<song>\", \"\").strip()\n",
        "\n",
        "  formatted_song = response[\"choices\"][0][\"text\"].strip()\n",
        "  formatted_song = formatted_song.replace('`', '\"')\n",
        "  formatted_song = formatted_song.replace(\" $ \", \"\\n\")\n",
        "  new_song = formatted_prompt+ \"\\n\" + formatted_song\n",
        "  print(new_song)\n",
        "  with open(\"new_song.abc\", \"w\") as new_song_file:\n",
        "    new_song_file.write(new_song)\n",
        "\n",
        "  song = music21.converter.parse(\"new_song.abc\")\n",
        "\n",
        "  part = song.parts[0]\n",
        "  chord_end = song.highestTime\n",
        "  for pi in reversed(range(len(part))):\n",
        "    p = part[pi]\n",
        "    for ni in reversed(range(len(p))):\n",
        "      n = p[ni]\n",
        "      if type(n) == music21.harmony.ChordSymbol:\n",
        "        chord_start = p.offset + n.offset\n",
        "        n.duration.quarterLength = chord_end - chord_start\n",
        "        n.volume = music21.volume.Volume(velocity=48)\n",
        "        chord_end = chord_start\n",
        "      elif type(n) == music21.note.Note:\n",
        "        n.volume = music21.volume.Volume(velocity=64)\n",
        "  file_name = \"song\" + str(i).zfill(2) + \".mid\"\n",
        "  song.write('midi', fp=file_name)\n",
        "\n",
        "  part = song.parts[0]\n",
        "  note_array = []\n",
        "\n",
        "  for p in part:\n",
        "    if isinstance(p, Iterable):\n",
        "      for n in p:\n",
        "        if type(n) == music21.note.Note:\n",
        "          note_array.append([int(n.pitch.ps), int(n.quarterLength*4+0.5)])\n",
        "\n",
        "  CMM = music_geometry_eval.calculate_time_supported_conjunct_melodic_motion(note_array)\n",
        "  LM = music_geometry_eval.calculate_time_supported_limited_macroharmony(note_array, span_size=32)\n",
        "  CENT = music_geometry_eval.calculate_time_supported_centricity(note_array, span_size=32)\n",
        "\n",
        "  print(\"  CMM :\", round(CMM, 4))\n",
        "  print(\"  LM  :\", round(LM, 4))\n",
        "  print(\"  CENT:\", round(CENT, 4))\n",
        "\n",
        "  norm_cmm = (CMM - CMM_mean) / CMM_std\n",
        "  norm_lm = (LM - LM_mean) / LM_std\n",
        "  norm_cent = (CENT - CENT_mean) / CMM_std\n",
        "\n",
        "  norm_score_squared = norm_cmm * norm_cmm + norm_lm * norm_lm + norm_cent * norm_cent\n",
        "  print(\"  NDM:\", round(norm_score_squared, 4))\n",
        "  score_arr = np.append(score_arr, norm_score_squared)\n",
        "\n",
        "  songs_with_scores.append([norm_score_squared, file_name])\n",
        "\n",
        "songs_with_scores.sort()\n",
        "for pair in songs_with_scores:\n",
        "  print(round(pair[0], 4), pair[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uKW0IhneCGl"
      },
      "source": [
        "# **Choose a Song and Play It**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e4wRsJQfDmk"
      },
      "source": [
        "song_number = 0\n",
        "\n",
        "melody_ns = note_seq.midi_file_to_sequence_proto(songs_with_scores[song_number][1])\n",
        "print(round(songs_with_scores[song_number][0], 4), songs_with_scores[song_number][1])\n",
        "\n",
        "note_seq.play_sequence( \n",
        "  melody_ns,\n",
        "  synth=note_seq.fluidsynth, sample_rate=SAMPLE_RATE, sf2_path=SF2_PATH)\n",
        "note_seq.plot_sequence(melody_ns)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
